{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classify  MNIST digits using a CNN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from time import time\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_nodes = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Upload the training and test data using the Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "block:loaddata"
    ]
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "prev:loaddata",
     "block:preprocess"
    ]
   },
   "outputs": [],
   "source": [
    "# Rescale pixels to be in the range [0,1]\n",
    "x_train = x_train.reshape((x_train.shape[0],28,28,1))/255.0\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)/255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "block:define_model",
     "prev:preprocess"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 542,230.0\n",
      "Trainable params: 542,230.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_nodes, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "block:compile_model",
     "prev:define_model"
    ]
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "block:train",
     "prev:compile_model"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9585Epoch 00000: val_loss improved from inf to 0.05945, saving model to saved_models/weights.best.hdf5\n",
      "60000/60000 [==============================] - 59s - loss: 0.1376 - acc: 0.9585 - val_loss: 0.0595 - val_acc: 0.9801\n"
     ]
    }
   ],
   "source": [
    "# Train for 1 epoch when using a CPU.\n",
    "epochs = 1\n",
    "\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=epochs, batch_size=32, callbacks=[checkpointer,tensorboard], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the model with the best validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "block:results",
     "prev:train"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.1400%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in x_test]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(y_test, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pipeline Metrics\n",
    "Use it to define the pipeline metrics that KFP will produce for every pipeline run. Kale will associate each one of these metrics to the steps that produced them. Also, you will have to choose one these metrics as the Katib search objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "pipeline-metrics"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.14\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "docker_image": "gcr.io/arrikto/jupyter-kale:v0.5.0-47-g2427cc9",
   "experiment": {
    "id": "new",
    "name": "mnist-classify"
   },
   "experiment_name": "mnist-classify",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "additionalMetricNames": [],
     "goal": 99.99,
     "objectiveMetricName": "test-accuracy",
     "type": "maximize"
    },
    "parallelTrialCount": 2,
    "parameters": [
     {
      "feasibleSpace": {
       "list": [
        "100",
        "150",
        "200"
       ]
      },
      "name": "num_nodes",
      "parameterType": "categorical"
     },
     {
      "feasibleSpace": {
       "list": [
        "0.01",
        "0.005",
        "0.001",
        "0.0005"
       ]
      },
      "name": "learning_rate",
      "parameterType": "categorical"
     }
    ]
   },
   "katib_run": false,
   "pipeline_description": "classification of mnist digists",
   "pipeline_name": "mnist-classification-cnn",
   "snapshot_volumes": true,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:access-rok:true"
   ],
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "workspace-classification-mro2j2nqs",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    },
    {
     "annotations": [],
     "mount_point": "/home/jovyan/data",
     "name": "data-5guxd2g5f",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
